{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single head attention block\n",
    "(For code below, see from ~1:01:30 in video)\n",
    "\n",
    "We consider this a <ins>decoder</ins> attention block specifically due to the mask preventing tokens from attending to future tokens within their sequence.\n",
    "\n",
    "And specifically this is <ins>self-attention</ins> as the keys, queries, and values are ALL produced from the same set of input tokens.  Consider that the keys and values could instead be injected from an encoder, while the queries come from an earlier layer in the decoder (this is called <ins>cross-attention</ins>) (see 1:16:05 in video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "\n",
    "# think of this as 4 sepearate sequences, each of 8 chars (with chars represented as 32 channel vectors)\n",
    "x = torch.randn(B,T,C)\n",
    "#print(\"x:\", x)\n",
    "\n",
    "head_size = 16  # size of resulting key and query vectors\n",
    "value_size = 16 # size of value representations created from each token\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, value_size, bias=False)\n",
    "\n",
    "k = key(x) # (B,T,head_size)\n",
    "q = query(x) # (B,T,head_size)\n",
    "assert k.shape == q.shape\n",
    "\n",
    "# now we multiply to get the dot product of respective key and query vectors for each sequence\n",
    "tmp = k.transpose(-2, -1) # swaps dims -2 and -1 -> (B, head_size, T)\n",
    "weights = q @ tmp # (B,T,head_size) @ (B,head_size,T) = (B, T, T)\n",
    "# weights now specify for each sequence the cross attention affinities between all token combinations\n",
    "\n",
    "\n",
    "# now we use a mask to prevent tokens from attending to future tokens in their sequence\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# note: replacing zeros in triangular matrix with -inf and taking softmax\n",
    "#  is equivalent to normalizing a lower triangular matrix of weights and zeros\n",
    "#  we also divide by sqrt(head_size) to normalize the variance, preventing a tendency to one-hot vectors after softmax\n",
    "weights = weights.masked_fill(tril == 0, float==('-inf')) * head_size**-0.5\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "# now we let the tokens in each sequence combine according to their respective attention affinities\n",
    "# in this case, the \"values\" would be the original tokens themselves\n",
    "#out = weights @ x # (B,T,T) @ (B,T,C) = (B,T,C)\n",
    "#assert out.shape == (B,T,C)\n",
    "\n",
    "# ACTUALLy we let their values combine according to query:key affinities\n",
    "v = weights @ value(x) # (B,T,T) @ (B, T, value_size) = (B,T,value_size)\n",
    "assert v.shape == (B,T,value_size)\n",
    "#weights[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7, 2, 0, 5],\n",
      "         [3, 5, 0, 4, 0],\n",
      "         [2, 0, 7, 6, 0]],\n",
      "\n",
      "        [[8, 1, 4, 9, 5],\n",
      "         [3, 6, 2, 0, 2],\n",
      "         [1, 6, 5, 9, 4]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 3, 2],\n",
       "         [7, 5, 0],\n",
       "         [2, 0, 7],\n",
       "         [0, 4, 6],\n",
       "         [5, 0, 0]],\n",
       "\n",
       "        [[8, 3, 1],\n",
       "         [1, 6, 6],\n",
       "         [4, 2, 5],\n",
       "         [9, 0, 9],\n",
       "         [5, 2, 4]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "x = torch.randint(0, 10, (2,3,5))\n",
    "print(x)\n",
    "x.transpose(-2, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
