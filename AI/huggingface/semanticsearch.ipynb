{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/learn/nlp-course/chapter5/6\n",
    "\n",
    "https://www.sbert.net/docs/pretrained_models.html#model-overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from finetune import get_device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
    "MODEL_ID = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModel.from_pretrained(MODEL_ID)\n",
    "model.to(device)\n",
    "\n",
    "def cls_pooling(model_output):\n",
    "    \"\"\"Collect the last hidden state for the special [CLS] token.\"\"\"\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 2048 lines from english.txt\n"
     ]
    }
   ],
   "source": [
    "fname = \"english.txt\"\n",
    "assert os.path.exists(fname)\n",
    "with open(fname, \"r\") as f:\n",
    "    lines = [line.strip() for line in f.readlines() if line.strip() != \"\"]\n",
    "\n",
    "print(f\"read {len(lines)} lines from {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 2048/2048 [00:24<00:00, 85.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "my_dataset = Dataset.from_dict({\"text\": lines})\n",
    "embeddings_dataset = my_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 571.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'embeddings'],\n",
       "    num_rows: 2048\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "\n",
    "#embeddings = get_embeddings(lines)\n",
    "#embeddings.shape\n",
    "#list(embeddings_dataset.data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat',\n",
       " 'kitten',\n",
       " 'pet',\n",
       " 'animal',\n",
       " 'what',\n",
       " 'define',\n",
       " 'category',\n",
       " 'example',\n",
       " 'need',\n",
       " 'this',\n",
       " 'usage',\n",
       " 'another',\n",
       " 'code',\n",
       " 'try',\n",
       " 'way',\n",
       " 'mystery',\n",
       " 'step',\n",
       " 'term',\n",
       " 'cause',\n",
       " 'issue',\n",
       " 'question',\n",
       " 'explain',\n",
       " 'biology',\n",
       " 'spell',\n",
       " 'dilemma',\n",
       " 'hurry',\n",
       " 'problem',\n",
       " 'word',\n",
       " 'trouble',\n",
       " 'program']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"cat\"\n",
    "query_embedding = get_embeddings([query]).cpu().detach().numpy()\n",
    "\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", query_embedding, k=30\n",
    ")\n",
    "\n",
    "display(samples[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
